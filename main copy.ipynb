{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro:\n",
    "This is an implementation of this: https://arxiv.org/pdf/2212.10717 paper on a Resnet34 model using CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass, field\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import threading\n",
    "import psutil\n",
    "import GPUtil  # You might need to install: pip install gputil\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetUtilizationRates  # pip install nvidia-ml-py3\n",
    "\n",
    "\n",
    "def optimize_for_speed(module_list=None):\n",
    "    \"\"\"Apply speed optimizations that don't require code changes\"\"\"\n",
    "    # Set environment variables for better performance\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "    os.environ[\"TORCH_CUDNN_V8_API_ENABLED\"] = \"1\"\n",
    "    \n",
    "    # Use TF32 on Ampere GPUs for faster mixed precision (negligible accuracy loss)\n",
    "    t.backends.cuda.matmul.allow_tf32 = True\n",
    "    t.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Enable cuDNN benchmarking\n",
    "    t.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # If using PyTorch 2.0+, compile your model\n",
    "    if hasattr(t, 'compile') and module_list:\n",
    "        for module in module_list:\n",
    "            t.compile(module)\n",
    "\n",
    "    # Clear GPU cache\n",
    "    t.cuda.empty_cache()\n",
    "    \n",
    "    print(\"Speed optimizations applied\")\n",
    "    \n",
    "\n",
    "def get_dataset():\n",
    "    # CIFAR100 Mean and Std\n",
    "    mean = (0.5071, 0.4867, 0.4408)\n",
    "    std = (0.2675, 0.2565, 0.2761)\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "    # Load the CIFAR-100 training and test datasets\n",
    "    trainset = tv.datasets.CIFAR100(root='data', train=True,\n",
    "                        download=True, transform=transform_train)\n",
    "\n",
    "    testset = tv.datasets.CIFAR100(root='data', train=False,\n",
    "                        download=True, transform=transform_test)\n",
    "    return trainset, testset\n",
    "\n",
    "trainset, testset = get_dataset()\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.4487329..1.5126765].\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJlpJREFUeJzt3X901PWd7/FXQDKgJBNCyC+TYPghoPxoRYlRS1FSIN11QXHrr97i6spKg1tlu2q6Vav1nFi722p7Ee/d7kLbI6J4BK/eilWUsNaAJYL8ULOAqYDkh2IzEwL5QeZ7//A6NprI901m+GTC83HOnEMyr7zzmXyTvPhmZj6T5HmeJwAATrIBrhcAADg1UUAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnDjN9QI+LxKJ6ODBg0pJSVFSUpLr5QAAjDzPU3Nzs3JzczVgQM/nOX2ugA4ePKj8/HzXywAA9NL+/fuVl5fX4/Vx+xPc0qVLddZZZ2nw4MEqKirSG2+84evjUlJS4rUkAMBJdLzf53EpoCeffFJLlizRvffeqzfffFNTpkzR7Nmz1djYeNyP5c9uANA/HPf3uRcH06ZN88rKyqJvd3Z2erm5uV5FRcVxPzYUCnmSuHDhwoVLgl9CodCX/r6P+RlQe3u7qqurVVJSEn3fgAEDVFJSoqqqqi/k29raFA6Hu1wAAP1fzAvoo48+Umdnp7Kysrq8PysrS/X19V/IV1RUKBgMRi88AAEATg3OnwdUXl6uUCgUvezfv9/1kgAAJ0HMH4adkZGhgQMHqqGhocv7GxoalJ2d/YV8IBBQIBCI9TIAAH1czM+AkpOTNXXqVK1fvz76vkgkovXr16u4uDjWnw4AkKDi8kTUJUuWaMGCBTr//PM1bdo0Pfzww2ppadHf/d3fxePTAQASUFwK6Oqrr9aHH36oe+65R/X19frKV76idevWfeGBCQCAU1eS53me60X8pXA4rGAw6HoZUf9q+PJY93A4w5AdZpxtWYv177DWpwpb/pdjPfIjDFnr8RlkzFscjWO+3Tg7ZMgeM87uMGSbjbNbDdmIcXanMW/5uljWLUltfWS26TaGwyoPBhUKhZSamtpjzvmj4AAApyYKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRFz2gutPLNvlWLdusXzxrbMt6042zraybN1j/R+RZduZI8bZluNj2XJGkv5kzO8wZGtqbRv9hFo+9p0tGH2mafaEIf6zeabJtu+VD42zrVsODTZkrVtCWWb3lTOKgT5zfWW9AIBTDAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOMFecMdh2VPNsO2VJNsebNYDFc995qz7ZFnWEojjbOt+bfWG7Cbj7Ir7nzDlayp+6T/cal2NZ8wbDD3Pd3T0VfNMo2fedK3v7IxLxphmF5jStp8J68+PhfXnJ2LIWr5LOn3mOAMCADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnEjyPC+O+3DYhcNhBYNB18uIWmX48qQYZ1u2zRjch2YnGfOW+e3G2dsN2f9+3za75q2dvrOP/+u/2ob/169tefTO6L82xf/x0X8z5efNOtuUt2gxZK0/P5btqY4YskfDYZUFgwqFQkpNTe0xxxkQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwgr3gjuN3hi/PUOPsQYbsacbZFta94Hre2al7zYbsHctfNM3+3d0/8x/+YJdptvSBMY9TVepff9d39n8/t9Q0O92QteztJtn2jjtqyB4Jh/X37AUHAOirYl5AP/rRj5SUlNTlMn78+Fh/GgBAgovLX3bOPfdcvfzyy599ktPi+QckAEAiiksznHbaacrOzo7HaABAPxGX+4B2796t3NxcjRo1Stdff7327dvXY7atrU3hcLjLBQDQ/8W8gIqKirRixQqtW7dOy5YtU21trb72ta+pubn7x0JVVFQoGAxGL/n5+bFeEgCgD4p5AZWWlupv//ZvNXnyZM2ePVu/+93v1NTUpKeeeqrbfHl5uUKhUPSyf//+WC8JANAHxf3RAWlpaTr77LO1Z8+ebq8PBAIKBALxXgYAoI+J+/OADh8+rL179yonJyfenwoAkEBiXkDf//73VVlZqT/96U96/fXXdcUVV2jgwIG69tprY/2pAAAJLOZ/gjtw4ICuvfZaHTp0SCNGjNAll1yiTZs2acSIEbH+VCfFMEPWuhVPPFm22EgyzrY+TvHqxXf7zr699AHjdMC98POP+s7ef88U0+zH7l/oO5tsmmxzzJD1u81YzAto1apVsR4JAOiH2AsOAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCLJ8zzP9SL+UjgcVjAYdL2MqK2GL4/1RSU6DFnLPkzW/BnG2U/ubjLlf3y2ZUc9oL+z7Yu5wmv0nR1rXEn3LxPavTZD9kg4rGuDQYVCIaWmpvaY4wwIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcOI01wvo64YYssnG2Z2GbMQ42/I/C8uWQJL0fx9fa/wI9Fa2IZupnrc+6U6jwr6z9abJ6N6HpvSmDbW+sxNmFJpmDzZkLb+v/BYLZ0AAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJ9oI7DsteSQONsy37zCUZZ3uG7DHj7NbGJuNH9H9Djfkbx51nyi+4stR39qysDNPs9973v9fYe3WNptn/9da7vrP/851tptmniqd++Z++s9fN+LFptuUMxPJ7wm+WMyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEe8EdxyBD1vrFTI7TOiSp05g3zW5vj+P0xPSdKZNM+Ttv/x+mfO6Maf7Dg23fiel1Y3xnz29qNs2+5K2zfWcD/277rv23XTtM+UT18br1vrPvybYXXIEhG4lDljMgAIAT5gLauHGjLr/8cuXm5iopKUlr167tcr3nebrnnnuUk5OjIUOGqKSkRLt3747VegEA/YS5gFpaWjRlyhQtXbq02+sfeugh/eIXv9Bjjz2mzZs364wzztDs2bPV2tra68UCAPoP831ApaWlKi3t/rVJPM/Tww8/rB/+8IeaO3euJOk3v/mNsrKytHbtWl1zzTW9Wy0AoN+I6X1AtbW1qq+vV0lJSfR9wWBQRUVFqqqq6vZj2traFA6Hu1wAAP1fTAuovr5ekpSVldXl/VlZWdHrPq+iokLBYDB6yc/Pj+WSAAB9lPNHwZWXlysUCkUv+/fvd70kAMBJENMCys7OliQ1NDR0eX9DQ0P0us8LBAJKTU3tcgEA9H8xLaDCwkJlZ2dr/frPnjgVDoe1efNmFRcXx/JTAQASnPlRcIcPH9aePXuib9fW1mrbtm1KT09XQUGBbrvtNj3wwAMaO3asCgsLdffddys3N1fz5s2L5boBAAnOXEBbtmzRpZdeGn17yZIlkqQFCxZoxYoVuuOOO9TS0qKFCxeqqalJl1xyidatW6fBgwfHbtUnUYoha9lax2qIMX/UkLVssSFJeeMKTfka4/y+YqySfGfzjH86bv74oG0xyYYjmjXSNjsy0H+20fZHk48bOnxnjxq3+bFsT+V/FX3QmcN9R61/0jpmyFpm+82aC2jGjBnyPK/H65OSknT//ffr/vvvt44GAJxCnD8KDgBwaqKAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOmLfiOdVY9oKLp3juM2f9X0hBQU5c1hFv45R1/NBfOH/c2b6zBxotu+9Jzzzxe1P+8rpG39mJf1Nqmq0m/zuCPf3bdabRL1Xt9J19p8G2K2GKAr6zH6vNNLsvmbXoO76zo42zLd+18dgLjjMgAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAm24kkQScb8UEPW/0Ysn3hv69vGj4gfy6ZAX8m0baz04YcNvrOnDUs3zT5ruG07o32vv+M7OzEj1zT7hco3fGdfrX7XNLsttcB3dt8x21Y8bTrDlE5UF31tmu9sqnG2Z8hajo7f3ymcAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACfYC66fsuwdZ/1fyNGGQ8aPiJ/LM/3vNXbT9TNNs09LHeE7G4nYvoqZx5pM+ca3/O9LV//eDtPsNzdt8J3Nyyk0zZ4w4wLf2fQ02159te/X+c5ubmwxza7rQ3vHjTgz33c2YJxtyVv3o/SDMyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACbbigQYa8w89UG7K3/T0c76zkcNVptnnF2b6zk47N8c0WyNH+c9+aNue6OOtb5nyjUMbfWcHpJ1hmh0cFvGdPVC7xzQ7r+h939kf/M3Zptl79qX7zj62+gPT7F83xW8rnozp3zXlL8nxf55gPaNINmQts4/FYSYAADFDAQEAnDAX0MaNG3X55ZcrNzdXSUlJWrt2bZfrb7jhBiUlJXW5zJkzJ1brBQD0E+YCamlp0ZQpU7R06dIeM3PmzFFdXV308sQTT/RqkQCA/sf8IITS0lKVlpZ+aSYQCCg7O/uEFwUA6P/ich/Qhg0blJmZqXHjxmnRokU6dKjnRwi1tbUpHA53uQAA+r+YF9CcOXP0m9/8RuvXr9dPfvITVVZWqrS0VJ2dnd3mKyoqFAwGo5f8fP+v/gcASFwxfx7QNddcE/33pEmTNHnyZI0ePVobNmzQzJlffEnk8vJyLVmyJPp2OBymhADgFBD3h2GPGjVKGRkZ2rOn+yewBQIBpaamdrkAAPq/uBfQgQMHdOjQIeXkGJ+FDgDo18x/gjt8+HCXs5na2lpt27ZN6enpSk9P13333af58+crOztbe/fu1R133KExY8Zo9uzZMV04ACCxmQtoy5YtuvTSS6Nvf3r/zYIFC7Rs2TJt375dv/71r9XU1KTc3FzNmjVLP/7xjxUIBGK3ajj19TNt+R+v+Jnv7Et3/sA0e3Byu/9wpNk0W4M7/GdHDDGNTh9ne5rCsHz/P6pJU79qmv1X7f5/Nre+/p5p9pgs//u1pU0w3vfb1OI7mt7ud3ey/78W20oUHP3F+7d78tvKnp9D2R3Ld4r/r8gnLN+1hp80+f3JMRfQjBkz5Hlej9e/+OKL1pEAgFMQe8EBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATsT89YCAz7tm/oW+s4d2fds0u+bp/+U7u2tH9y8J0pNzDh/2nT3SbNkpSzpjWNCUT8o17O+217aWYaf739zv7LGDTLM/+OBD39nA6Smm2e980OQ/e+SoaXaKRpjy/1DxL76z00yTpQZDNmKcbTkDsZSF3yxnQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATbMWDuEsyZP/hnhtNs5e3N/nObvrD/zHN7gj5376lYd9+0+yUwZmm/Pixkwxp24/1vv2NvrNv7XjTNLs59Gff2V1jD5pmV34U9p398yTL10/6hwceMOW/9TeX+s7aNgWynSVYzyiOGfOxxhkQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwgr3gEHeeITvIOHv0dd/2nf3tytWm2SOG+l/NpHOnmGYPag2Y8umphr3jkm2z//T++76zBz/0v7ebJCUPDvrO7jzYYZq95dhA39lv/ecjptkLLrnElG8xZNtNk22/pG1fQZtIHLKcAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOsBUP4i4pjrOzzvG/Rc3hkeNMs9e+tt53NiN9qmn2RZeMN+WlY/6j4ZBp8qgpI31nR4cvMs1+cdN/+84+07jDNHv4hG/6zp5v3Fqn1ZS25YcYZ1sk2hlFoq0XANBPmAqooqJCF1xwgVJSUpSZmal58+appqamS6a1tVVlZWUaPny4hg4dqvnz56uhoSGmiwYAJD5TAVVWVqqsrEybNm3SSy+9pI6ODs2aNUstLZ/tBXv77bfrueee0+rVq1VZWamDBw/qyiuvjPnCAQCJzXQf0Lp167q8vWLFCmVmZqq6ulrTp09XKBTSf/zHf2jlypW67LLLJEnLly/XhAkTtGnTJl144YWxWzkAIKH16j6gUOiTOzvT09MlSdXV1ero6FBJSUk0M378eBUUFKiqqqrbGW1tbQqHw10uAID+74QLKBKJ6LbbbtPFF1+siRMnSpLq6+uVnJystLS0LtmsrCzV19d3O6eiokLBYDB6yc/PP9ElAQASyAkXUFlZmXbu3KlVq1b1agHl5eUKhULRy/79+3s1DwCQGE7oeUCLFy/W888/r40bNyovLy/6/uzsbLW3t6upqanLWVBDQ4Oys7O7nRUIBBQI2F5CGACQ+ExnQJ7nafHixVqzZo1eeeUVFRYWdrl+6tSpGjRokNav/+wJfDU1Ndq3b5+Ki4tjs2IAQL9gOgMqKyvTypUr9eyzzyolJSV6v04wGNSQIUMUDAZ10003acmSJUpPT1dqaqpuvfVWFRcX8wg4AEAXpgJatmyZJGnGjBld3r98+XLdcMMNkqSf//znGjBggObPn6+2tjbNnj1bjz76aEwWCwDoP0wF5HnecTODBw/W0qVLtXTp0hNeFODXREP2rxbeYpr979e97Dv74uZ3TLMLxmaY8nnnnek/nBU0zY6863/vuHc+PGya/UJrne9sk2z3BY8Z+1XfWevebh3G/GBD1rCrnyTbWo4YZ3cashFD1u+a2QsOAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcOKEXo4B6CuOvznUZ3bt6P5FEXvSrKG+s2/UfGCa3fToWlN+XF6K7+xpx5JNsw8cHuQ7uyNs+5VxwfRv+85edOPfm2aP++ZFvrMtpsnSh8Z8liFr3ebHso2QdbZle514zOUMCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOMFecEhoewzZbbveMs0+po98Z88abPtRyh48xJQfdFrQd7Y52TY7fdwk39l//Jb/vd0kafoV031nB5omS7WG7DvG2SFjvsCQte3UJyXFcfYRQ9a6z5wfnAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATrAVDxJatiEbCteZZn+sQ/7XkTrcNPusVP9b60jSkOE5vrNFV803zZ684O9N+b5imCE70TjbM+YffeBJ39lDh+tNsxc9+D3f2RTTZKnFkLVsT+R3LmdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACfaCQ0KLdPrPXvTVCabZzRv97+82YHi+aXZ7xLYX3ISvft13NlH3drNKi1NWkmp//UdT/oW7r/Gd3WNcy55Vq3xnb/zDC6bZ556Z5jt71DC3w2eOMyAAgBOmAqqoqNAFF1yglJQUZWZmat68eaqpqemSmTFjhpKSkrpcbrnllpguGgCQ+EwFVFlZqbKyMm3atEkvvfSSOjo6NGvWLLW0dN18++abb1ZdXV308tBDD8V00QCAxGe6D2jdunVd3l6xYoUyMzNVXV2t6dOnR99/+umnKzvb8kotAIBTTa/uAwqFPnmJovT09C7vf/zxx5WRkaGJEyeqvLxcR44c6XFGW1ubwuFwlwsAoP874UfBRSIR3Xbbbbr44os1ceJnrzd43XXXaeTIkcrNzdX27dt15513qqamRs8880y3cyoqKnTfffed6DIAAAnqhAuorKxMO3fu1Guvvdbl/QsXLoz+e9KkScrJydHMmTO1d+9ejR49+gtzysvLtWTJkujb4XBY+fm2h7QCABLPCRXQ4sWL9fzzz2vjxo3Ky8v70mxRUZEkac+ePd0WUCAQUCAQOJFlAAASmKmAPM/TrbfeqjVr1mjDhg0qLCw87sds27ZNkpSTk3NCCwQA9E+mAiorK9PKlSv17LPPKiUlRfX19ZKkYDCoIUOGaO/evVq5cqW++c1vavjw4dq+fbtuv/12TZ8+XZMnT47LDQAAJCZTAS1btkzSJ082/UvLly/XDTfcoOTkZL388st6+OGH1dLSovz8fM2fP18//OEPY7ZgAED/YP4T3JfJz89XZWVlrxaEvq/l+JEunvr9Xt/ZN3/7O9PsSSNzfWfHZmSaZv/5r7/lOxtMSz9+6C/XkpJlyp817SJTHr3z7n+uMOX979Rny0rStvc3+c7+Ks/2AK5Lvv0vvrPTH7zLdzbS7C/HXnAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAE0ne8fbXOcnC4bCCwaDrZUTF9cuzxZA9P26r0JYGW/5opN2Uj/zZ/6vcfiU/wzQ7mOI/GwodM83etnWP7+yBt94zzY58sN+U/2rxON/ZiVfMMM3GFz0RnGHKHwj734LM5y41UZafNttPpvS+ITtQ5/rOdqhTa/WuQqGQUlNTe8xxBgQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJw4zfUC+rqjy9/2nf2w9gPT7IKyb1iXExdTs2z5JCXbPiDHtr9bvASDtm/3r88Y7z9syeKka9r9sSl/LNxkyxuyEdNk21nCYOPsQkP2I+3ynfW7Jx1nQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATbMVzHPX//qzvbOGr5bbhAeNi4iTJ9QJ6Ydfrb/nOJg8eZJo99rxzrMvBSdRsyEY6QqbZZwywbK4jDTHsr+N3m5pPdRiy8dzmZ4Ih2xqHzw8AQMxQQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIAT7AV3HIWvG/d3w0mVc2aW72x6ZkYcV4KTLcUSDp5hmt0Rse0dZ9mvzfpLN8eQDRpn1xmyln3mOn3mOAMCADhhKqBly5Zp8uTJSk1NVWpqqoqLi/XCCy9Er29tbVVZWZmGDx+uoUOHav78+WpoaIj5ogEAic9UQHl5eXrwwQdVXV2tLVu26LLLLtPcuXO1a9cuSdLtt9+u5557TqtXr1ZlZaUOHjyoK6+8Mi4LBwAktiTP87zeDEhPT9dPf/pTXXXVVRoxYoRWrlypq666SpL07rvvasKECaqqqtKFF17oa144HFYwaP1LZvz08suDOPv4/XrfWfN9QEO4i7Tf+KDRFH8yb6opv08HfGetrwc0wpDtK/cBtUr6F0mhUEipqak95k74PqDOzk6tWrVKLS0tKi4uVnV1tTo6OlRSUhLNjB8/XgUFBaqqqupxTltbm8LhcJcLAKD/MxfQjh07NHToUAUCAd1yyy1as2aNzjnnHNXX1ys5OVlpaWld8llZWaqv7/l/qRUVFQoGg9FLfn6++UYAABKPuYDGjRunbdu2afPmzVq0aJEWLFigt99++4QXUF5erlAoFL3s37//hGcBABKH+Y/cycnJGjNmjCRp6tSp+uMf/6hHHnlEV199tdrb29XU1NTlLKihoUHZ2dk9zgsEAgoEAvaVAwASWq+fBxSJRNTW1qapU6dq0KBBWr9+ffS6mpoa7du3T8XFxb39NACAfsZ0BlReXq7S0lIVFBSoublZK1eu1IYNG/Tiiy8qGAzqpptu0pIlS5Senq7U1FTdeuutKi4u9v0IOADAqcNUQI2NjfrOd76juro6BYNBTZ48WS+++KK+8Y1vSJJ+/vOfa8CAAZo/f77a2to0e/ZsPfroo3FZOCBJ6SN7/vMuENVuu7dhoPGPQ5aHP1sfhm2Zbf1pSDNk2wzZIz5zvX4eUKzxPCAAMVf7sSn+9KivmvIfa5/vbDyfB2QtoFZD1lpA1yqOzwMCAKA3KCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAn+txLPva1nQd4gTygH2i2/RwfMb3+p3TUkLXuhOB3WxtJajHOtuyEYFn3p2s+3u/zPldAzc3NrpfQRV/aFggAEklzc/OX/g7tc3vBRSIRHTx4UCkpKUpKSoq+PxwOKz8/X/v37//SvYUSHbez/zgVbqPE7exvYnE7Pc9Tc3OzcnNzNWBAz/f09LkzoAEDBigvL6/H61NTU/v1wf8Ut7P/OBVuo8Tt7G96ezv9/PWIByEAAJyggAAATiRMAQUCAd17770KBAKulxJX3M7+41S4jRK3s785mbezzz0IAQBwakiYMyAAQP9CAQEAnKCAAABOUEAAACcSpoCWLl2qs846S4MHD1ZRUZHeeOMN10uKqR/96EdKSkrqchk/frzrZfXKxo0bdfnllys3N1dJSUlau3Ztl+s9z9M999yjnJwcDRkyRCUlJdq9e7ebxfbC8W7nDTfc8IVjO2fOHDeLPUEVFRW64IILlJKSoszMTM2bN081NTVdMq2trSorK9Pw4cM1dOhQzZ8/Xw0NDY5WfGL83M4ZM2Z84XjecsstjlZ8YpYtW6bJkydHn2xaXFysF154IXr9yTqWCVFATz75pJYsWaJ7771Xb775pqZMmaLZs2ersbHR9dJi6txzz1VdXV308tprr7leUq+0tLRoypQpWrp0abfXP/TQQ/rFL36hxx57TJs3b9YZZ5yh2bNnq7XVskWie8e7nZI0Z86cLsf2iSeeOIkr7L3KykqVlZVp06ZNeumll9TR0aFZs2appeWz7S9vv/12Pffcc1q9erUqKyt18OBBXXnllQ5XbefndkrSzTff3OV4PvTQQ45WfGLy8vL04IMPqrq6Wlu2bNFll12muXPnateuXZJO4rH0EsC0adO8srKy6NudnZ1ebm6uV1FR4XBVsXXvvfd6U6ZMcb2MuJHkrVmzJvp2JBLxsrOzvZ/+9KfR9zU1NXmBQMB74oknHKwwNj5/Oz3P8xYsWODNnTvXyXripbGx0ZPkVVZWep73ybEbNGiQt3r16mjmnXfe8SR5VVVVrpbZa5+/nZ7neV//+te9733ve+4WFSfDhg3zfvWrX53UY9nnz4Da29tVXV2tkpKS6PsGDBigkpISVVVVOVxZ7O3evVu5ubkaNWqUrr/+eu3bt8/1kuKmtrZW9fX1XY5rMBhUUVFRvzuukrRhwwZlZmZq3LhxWrRokQ4dOuR6Sb0SCoUkSenp6ZKk6upqdXR0dDme48ePV0FBQUIfz8/fzk89/vjjysjI0MSJE1VeXq4jRywvmtC3dHZ2atWqVWppaVFxcfFJPZZ9bjPSz/voo4/U2dmprKysLu/PysrSu+++62hVsVdUVKQVK1Zo3Lhxqqur03333aevfe1r2rlzp1JSUlwvL+bq6+slqdvj+ul1/cWcOXN05ZVXqrCwUHv37tUPfvADlZaWqqqqSgMHDnS9PLNIJKLbbrtNF198sSZOnCjpk+OZnJystLS0LtlEPp7d3U5Juu666zRy5Ejl5uZq+/btuvPOO1VTU6NnnnnG4WrtduzYoeLiYrW2tmro0KFas2aNzjnnHG3btu2kHcs+X0CnitLS0ui/J0+erKKiIo0cOVJPPfWUbrrpJocrQ29dc8010X9PmjRJkydP1ujRo7VhwwbNnDnT4cpOTFlZmXbu3Jnw91EeT0+3c+HChdF/T5o0STk5OZo5c6b27t2r0aNHn+xlnrBx48Zp27ZtCoVCevrpp7VgwQJVVlae1DX0+T/BZWRkaODAgV94BEZDQ4Oys7MdrSr+0tLSdPbZZ2vPnj2ulxIXnx67U+24StKoUaOUkZGRkMd28eLFev755/Xqq692edmU7Oxstbe3q6mpqUs+UY9nT7ezO0VFRZKUcMczOTlZY8aM0dSpU1VRUaEpU6bokUceOanHss8XUHJysqZOnar169dH3xeJRLR+/XoVFxc7XFl8HT58WHv37lVOTo7rpcRFYWGhsrOzuxzXcDiszZs39+vjKkkHDhzQoUOHEurYep6nxYsXa82aNXrllVdUWFjY5fqpU6dq0KBBXY5nTU2N9u3bl1DH83i3szvbtm2TpIQ6nt2JRCJqa2s7uccypg9piJNVq1Z5gUDAW7Fihff22297Cxcu9NLS0rz6+nrXS4uZf/qnf/I2bNjg1dbWen/4wx+8kpISLyMjw2tsbHS9tBPW3Nzsbd261du6dasnyfvZz37mbd261Xv//fc9z/O8Bx980EtLS/OeffZZb/v27d7cuXO9wsJC7+jRo45XbvNlt7O5udn7/ve/71VVVXm1tbXeyy+/7J133nne2LFjvdbWVtdL923RokVeMBj0NmzY4NXV1UUvR44ciWZuueUWr6CgwHvllVe8LVu2eMXFxV5xcbHDVdsd73bu2bPHu//++70tW7Z4tbW13rPPPuuNGjXKmz59uuOV29x1111eZWWlV1tb623fvt276667vKSkJO/3v/+953kn71gmRAF5nuf98pe/9AoKCrzk5GRv2rRp3qZNm1wvKaauvvpqLycnx0tOTvbOPPNM7+qrr/b27Nnjelm98uqrr3qSvnBZsGCB53mfPBT77rvv9rKysrxAIODNnDnTq6mpcbvoE/Blt/PIkSPerFmzvBEjRniDBg3yRo4c6d18880J95+n7m6fJG/58uXRzNGjR73vfve73rBhw7zTTz/du+KKK7y6ujp3iz4Bx7ud+/bt86ZPn+6lp6d7gUDAGzNmjPfP//zPXigUcrtwoxtvvNEbOXKkl5yc7I0YMcKbOXNmtHw87+QdS16OAQDgRJ+/DwgA0D9RQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwIn/B65KdTYzRXrFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img: t.Tensor):\n",
    "  img = img / 2 + 0.5  # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "# Get a random image from the trainset\n",
    "image, label = trainset[3]\n",
    "\n",
    "# Display the image\n",
    "imshow(image)\n",
    "print(classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_monitoring_thread(stop_event, log_file='gpu_stats.csv'):\n",
    "    \"\"\"Thread function to monitor GPU usage and log it to a file.\"\"\"\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        device_handle = nvmlDeviceGetHandleByIndex(0)  # First GPU\n",
    "        \n",
    "        # Create log file and write header\n",
    "        with open(log_file, 'w') as f:\n",
    "            f.write(\"timestamp,gpu_util(%),memory_used(MB),memory_total(MB),memory_util(%),temperature(C)\\n\")\n",
    "        \n",
    "        last_printed = 0  # To limit console output frequency\n",
    "        while not stop_event.is_set():\n",
    "            try:\n",
    "                # Get GPU statistics\n",
    "                util = nvmlDeviceGetUtilizationRates(device_handle)\n",
    "                mem_info = nvmlDeviceGetMemoryInfo(device_handle)\n",
    "                \n",
    "                # Format and log statistics\n",
    "                timestamp = time.time()\n",
    "                gpu_util = util.gpu\n",
    "                mem_used = mem_info.used / 1024 / 1024  # Convert to MB\n",
    "                mem_total = mem_info.total / 1024 / 1024  # Convert to MB\n",
    "                mem_util = 100 * mem_info.used / mem_info.total\n",
    "                \n",
    "                # Get GPU temperature (optional, may not work on all GPUs)\n",
    "                gpu_temp = GPUtil.getGPUs()[0].temperature\n",
    "                \n",
    "                # Write to log file\n",
    "                with open(log_file, 'a') as f:\n",
    "                    f.write(f\"{timestamp},{gpu_util},{mem_used:.2f},{mem_total:.2f},{mem_util:.2f},{gpu_temp}\\n\")\n",
    "                \n",
    "                # Print current stats to console less frequently (every 5 seconds)\n",
    "                current_time = time.time()\n",
    "                if current_time - last_printed >= 5:\n",
    "                    print(f\"\\rGPU: {gpu_util}% | Mem: {mem_used/1024:.1f}/{mem_total/1024:.1f}GB ({mem_util:.1f}%)\", end=\"\", flush=True)\n",
    "                    last_printed = current_time\n",
    "                \n",
    "                # Sleep until next update\n",
    "                time.sleep(1)  # Update every second\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in GPU monitoring: {e}\")\n",
    "                time.sleep(5)  # Retry after 5 seconds\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize GPU monitoring: {e}\")\n",
    "\n",
    "\n",
    "def setup_nvidia_smi_logging(log_interval=5, log_file=\"nvidia_smi_log.txt\"):\n",
    "    \"\"\"Start a separate process to log nvidia-smi output at regular intervals\"\"\"\n",
    "    # First clear the log file if it exists\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(f\"NVIDIA-SMI Log started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    # Command to run nvidia-smi periodically and log to file (use > instead of >> to overwrite each time)\n",
    "    # Use a compact format with only essential information\n",
    "    cmd = f'while true; do (echo \"$(date)\" && nvidia-smi --format=csv,noheader --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu,power.draw) > {log_file}; sleep {log_interval}; done'\n",
    "    process = subprocess.Popen(cmd, shell=True)\n",
    "    return process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from tqdm import tqdm\n",
    "\n",
    "@dataclass\n",
    "class ResNetTrainingArgs:\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 200\n",
    "    n_classes: int = 100\n",
    "    optimizer: t.optim.Optimizer = t.optim.SGD\n",
    "    optimizer_args: dict[str, float] = field(default_factory=lambda: {\"lr\": 0.1, \"momentum\": 0.9, \"weight_decay\": 5e-4})\n",
    "    scheduler: t.optim.lr_scheduler = t.optim.lr_scheduler.MultiStepLR\n",
    "    scheduler_args: dict[str, float] = field(default_factory=lambda: {\"milestones\": [60, 120, 160], \"gamma\": 0.2})\n",
    "    mixed_precision: bool = True\n",
    "    num_workers: int = 8\n",
    "    pin_memory: bool = True\n",
    "    prefetch_factor: int = 2\n",
    "    benchmark: bool = True\n",
    "    compile_model: bool = True\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    monitor_gpu: bool = True\n",
    "    monitor_interval: float = 5.0  # seconds between GPU monitoring updates\n",
    "\n",
    "\n",
    "def train_and_validate(args: ResNetTrainingArgs, model: nn.Module, device: t.device) -> tuple[list[float], list[float], list[float], nn.Module]:\n",
    "    \"\"\"\n",
    "    Trains and validates the ResNet model with optimized performance.\n",
    "    \"\"\"\n",
    "    # Enable cuDNN benchmarking for faster convolutions\n",
    "    if args.benchmark:\n",
    "        t.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Use PyTorch 2.0+ model compilation for faster execution\n",
    "    if args.compile_model and hasattr(t, 'compile'):\n",
    "        model = t.compile(model)\n",
    "    \n",
    "    optimizer = args.optimizer(model.parameters(), **args.optimizer_args)\n",
    "    scheduler = args.scheduler(optimizer, **args.scheduler_args)\n",
    "    \n",
    "    # Initialize gradient scaler for mixed precision training - updated to newer PyTorch API\n",
    "    scaler = GradScaler(device='cuda', enabled=args.mixed_precision)\n",
    "\n",
    "    # Load dataset with optimized DataLoader settings\n",
    "    trainset, testset = get_dataset()\n",
    "    trainloader = DataLoader(\n",
    "        trainset, \n",
    "        batch_size=args.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_memory,\n",
    "        prefetch_factor=args.prefetch_factor,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    testloader = DataLoader(\n",
    "        testset, \n",
    "        batch_size=args.batch_size * 2,  # Can use larger batch size for inference\n",
    "        shuffle=False, \n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_memory,\n",
    "        prefetch_factor=args.prefetch_factor,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    # Start GPU monitoring if requested\n",
    "    stop_monitoring = threading.Event()\n",
    "    monitoring_thread = None\n",
    "    if args.monitor_gpu:\n",
    "        print(\"Starting GPU monitoring...\")\n",
    "        monitoring_thread = threading.Thread(\n",
    "            target=gpu_monitoring_thread, \n",
    "            args=(stop_monitoring,),\n",
    "            daemon=True\n",
    "        )\n",
    "        monitoring_thread.start()\n",
    "\n",
    "    # Lists to store metrics\n",
    "    loss_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        pbar_train = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Zero gradients at the beginning of each epoch rather than each batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for i, (imgs, labels) in enumerate(pbar_train):\n",
    "            # Move data to device with non-blocking transfer\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Use mixed precision training - updated to newer PyTorch API\n",
    "            with autocast(device_type='cuda', enabled=args.mixed_precision):\n",
    "                logits = model(imgs)\n",
    "                loss = F.cross_entropy(logits, labels)\n",
    "                loss = loss / args.gradient_accumulation_steps  # Scale loss for gradient accumulation\n",
    "            \n",
    "            # Use gradient scaling to prevent underflow\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient accumulation - only update every n steps\n",
    "            if (i + 1) % args.gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Update metrics\n",
    "            with t.no_grad():\n",
    "                running_loss += loss.item() * args.gradient_accumulation_steps\n",
    "                predicted = t.argmax(logits, dim=-1)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                total_train += labels.size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            pbar_train.set_postfix(loss=f\"{running_loss/(i+1):.3f}\", train_acc=f\"{train_accuracy:.2f}%\")\n",
    "\n",
    "        # Record metrics for the epoch\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        loss_list.append(epoch_loss)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "        # ----------------------\n",
    "        # Validation Loop\n",
    "        # ----------------------\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with t.inference_mode():\n",
    "            for imgs, labels in testloader:\n",
    "                imgs = imgs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                with autocast(device_type='cuda', enabled=args.mixed_precision):\n",
    "                    logits = model(imgs)\n",
    "                \n",
    "                predicted = t.argmax(logits, dim=-1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{args.epochs}] - Train Acc: {train_accuracy:.2f}% | Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Stop GPU monitoring if it was started\n",
    "    if args.monitor_gpu and monitoring_thread is not None:\n",
    "        stop_monitoring.set()\n",
    "        monitoring_thread.join(timeout=1.0)\n",
    "        print(\"\\nGPU monitoring stopped\")\n",
    "\n",
    "    return loss_list, train_accuracy_list, val_accuracy_list, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA L40S\n",
      "CUDA Version: 12.4\n",
      "Number of GPUs: 4\n",
      "\n",
      "GPU Memory before training:\n",
      "GPU 0: NVIDIA L40S\n",
      "  Total memory: 44.43 GB\n",
      "  Memory allocated: 1.23 GB\n",
      "  Memory reserved: 1.53 GB\n",
      "GPU 1: NVIDIA L40S\n",
      "  Total memory: 44.43 GB\n",
      "  Memory allocated: 0.00 GB\n",
      "  Memory reserved: 0.00 GB\n",
      "GPU 2: NVIDIA L40S\n",
      "  Total memory: 44.43 GB\n",
      "  Memory allocated: 0.00 GB\n",
      "  Memory reserved: 0.00 GB\n",
      "GPU 3: NVIDIA L40S\n",
      "  Total memory: 44.43 GB\n",
      "  Memory allocated: 0.00 GB\n",
      "  Memory reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "from widenet import WideNet\n",
    "    \n",
    "# Use CUDA by default for L40s GPU\n",
    "device = t.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if t.cuda.is_available():\n",
    "  print(f\"GPU: {t.cuda.get_device_name(0)}\")\n",
    "  print(f\"CUDA Version: {t.version.cuda}\")\n",
    "  print(f\"Number of GPUs: {t.cuda.device_count()}\")\n",
    "  \n",
    "  # Print GPU memory info before training\n",
    "  print(\"\\nGPU Memory before training:\")\n",
    "  for i in range(t.cuda.device_count()):\n",
    "      print(f\"GPU {i}: {t.cuda.get_device_properties(i).name}\")\n",
    "      print(f\"  Total memory: {t.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "      print(f\"  Memory allocated: {t.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "      print(f\"  Memory reserved: {t.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "\n",
    "# Optional: Start nvidia-smi logging in background\n",
    "nvidia_smi_process = setup_nvidia_smi_logging(log_interval=10)\n",
    "\n",
    "# Optimized training arguments\n",
    "training_args = ResNetTrainingArgs(\n",
    "  batch_size=256,                 # Increased batch size for better GPU utilization\n",
    "  epochs=200,\n",
    "  n_classes=100,\n",
    "  optimizer=t.optim.SGD,\n",
    "  optimizer_args={\"lr\": 0.1, \"momentum\": 0.9, \"weight_decay\": 5e-4},\n",
    "  scheduler=t.optim.lr_scheduler.MultiStepLR,\n",
    "  scheduler_args={\"milestones\": [60, 120, 160], \"gamma\": 0.2},\n",
    "  mixed_precision=True,          # Enable mixed precision training\n",
    "  num_workers=8,                 # Optimize based on CPU cores\n",
    "  pin_memory=True,               # Speed up CPU to GPU transfers\n",
    "  prefetch_factor=2,             # Prefetch batches for better throughput\n",
    "  benchmark=True,                # Enable cuDNN benchmarking\n",
    "  compile_model=True,            # Use PyTorch 2.0+ compilation\n",
    "  gradient_accumulation_steps=1, # Increase if OOM errors occur\n",
    "  monitor_gpu=True,              # Enable GPU monitoring\n",
    "  monitor_interval=5.0           # Update monitoring stats every 5 seconds\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "widenet28 = WideNet(n_classes=100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "loss_list, train_accuracy_list, val_accuracy_list, trained_model = train_and_validate(\n",
    "  training_args, widenet28, device\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Kill nvidia-smi logging process if it was started\n",
    "if 'nvidia_smi_process' in locals():\n",
    "  nvidia_smi_process.terminate()\n",
    "  print(\"Nvidia-smi logging stopped\")\n",
    "\n",
    "# Print GPU memory info after training\n",
    "if t.cuda.is_available():\n",
    "  print(\"\\nGPU Memory after training:\")\n",
    "  for i in range(t.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {t.cuda.get_device_properties(i).name}\")\n",
    "    print(f\"  Memory allocated: {t.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Memory reserved: {t.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "      \n",
    "print(\"\\nTraining statistics have been saved to:\")\n",
    "print(\"- gpu_stats.csv - Detailed GPU utilization metrics\")\n",
    "print(\"- nvidia_smi_log.txt - Raw nvidia-smi output logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import OrderedDict\n",
    "\n",
    "# Initialize model\n",
    "widenet28 = WideNet(n_classes=100).to(device)\n",
    "\n",
    "checkpoint_path = \"checkpoints/widenet_best.pt\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = t.load(checkpoint_path)\n",
    "\n",
    "\n",
    "untrained_model_state = widenet28.state_dict()\n",
    "checkpoint_model_state: OrderedDict = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "state_to_load = {\n",
    "  key: pretrained_value for (key, value), (pretrained_key, pretrained_value) in zip(untrained_model_state.items(), checkpoint_model_state.items())\n",
    "}\n",
    "\n",
    "# Load the model weights\n",
    "widenet28.load_state_dict(state_to_load)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "widenet28.eval()\n",
    "\n",
    "\n",
    "print(\"Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.09"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_val = 0\n",
    "total_val = 0\n",
    "val_accuracy_list = []\n",
    "\n",
    "testloader = DataLoader(\n",
    "  testset, \n",
    "  batch_size=training_args.batch_size * 2,  # Can use larger batch size for inference\n",
    "  shuffle=False, \n",
    "  num_workers=training_args.num_workers,\n",
    "  pin_memory=training_args.pin_memory,\n",
    "  prefetch_factor=training_args.prefetch_factor,\n",
    "  persistent_workers=True\n",
    ")\n",
    "\n",
    "with t.inference_mode():\n",
    "  for imgs, labels in testloader:\n",
    "    imgs = imgs.to(device, non_blocking=True)\n",
    "    labels = labels.to(device, non_blocking=True)\n",
    "    \n",
    "    with autocast(device_type='cuda', enabled=training_args.mixed_precision):\n",
    "      logits = widenet28(imgs)\n",
    "    \n",
    "    predicted = t.argmax(logits, dim=-1)\n",
    "    correct_val += (predicted == labels).sum().item()\n",
    "    total_val += labels.size(0)\n",
    "\n",
    "val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "val_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
